{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install azure-storage-blob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjHqX0dtq_N7",
        "outputId": "baa17a82-915c-4b59-cf67-12d51e593cf4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: azure-storage-blob in /usr/local/lib/python3.10/dist-packages (12.16.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (1.27.1)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (40.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (4.5.0)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob) (0.6.1)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.26.0->azure-storage-blob) (2.27.1)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core<2.0.0,>=1.26.0->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.21)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->azure-core<2.0.0,>=1.26.0->azure-storage-blob) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import json\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
        "from azure.core.pipeline.transport import HttpResponse"
      ],
      "metadata": {
        "id": "eX9ESwu3gcPv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(date, time):\n",
        "\n",
        "    url = \"https://data.gharchive.org/\"+ str(date) +'-'+ str(time) +'.json.gz'\n",
        "    print(url)\n",
        "\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "\n",
        "       with open(\"cache.json.gz\", \"wb\") as file:\n",
        "\n",
        "            file.write(response.content)\n",
        "\n",
        "       print(\"File downloaded successfully.\")\n",
        "\n",
        "    else:\n",
        "\n",
        "       print(\"Error downloading the file.\")\n"
      ],
      "metadata": {
        "id": "aEH6n8xYekC7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_payload(row):\n",
        "    formatted_payload = {\n",
        "        'action': row['action'],\n",
        "        'issue.url': row['issue']['url'],\n",
        "        'issue.number': row['issue']['number'],\n",
        "        'issue.title': row['issue']['title'],\n",
        "        'issue.user.login': row['issue']['user']['login'],\n",
        "        'issue.user.type': row['issue']['user']['type'],\n",
        "        'issue.user.site_admin': row['issue']['user']['site_admin'],\n",
        "        'issue.labels': json.dumps(row['issue']['labels']),\n",
        "        'issue.state': row['issue']['state'],\n",
        "        'issue.locked': row['issue']['locked'],\n",
        "        'issue.milestone': json.dumps(row['issue']['milestone']),\n",
        "        'issue.comments': row['issue']['comments'],\n",
        "        'issue.created_at': row['issue']['created_at'],\n",
        "        'issue.updated_at': row['issue']['updated_at'],\n",
        "        'issue.closed_at': row['issue']['closed_at'],\n",
        "        'issue.author_association': row['issue']['author_association'],\n",
        "        'issue.active_lock_reason': row['issue']['active_lock_reason'],\n",
        "        'issue.body': row['issue']['body'],\n",
        "        'issue.performed_via_github_app': json.dumps(row['issue']['performed_via_github_app']),\n",
        "        'issue.state_reason': row['issue']['state_reason']\n",
        "    }\n",
        "    return formatted_payload"
      ],
      "metadata": {
        "id": "ctWCOfCbqVNC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_data():\n",
        "  filename = \"cache.json.gz\"\n",
        "  df = pd.read_json(filename, compression=\"gzip\", lines=True).drop('id', axis=1)\n",
        "  actor_flat = pd.json_normalize(df['actor']).add_prefix('actor.').drop('actor.id', axis=1)\n",
        "  df = pd.concat([df.drop('actor', axis=1), actor_flat], axis=1)\n",
        "  repo_flat = pd.json_normalize(df['repo']).add_prefix('repo.').drop('repo.id', axis=1)\n",
        "  df = pd.concat([df.drop('repo', axis=1), repo_flat], axis=1)\n",
        "  org_flat = pd.json_normalize(df['org']).add_prefix('org.').drop('org.id', axis=1)\n",
        "  df = pd.concat([df.drop('org', axis=1), org_flat], axis=1)\n",
        "  issues_df = df[df['type']=='IssuesEvent']\n",
        "  issues_df['payload'] = issues_df['payload'].apply(lambda row: format_payload(row))\n",
        "  payload_flat = pd.json_normalize(issues_df['payload']).add_prefix('payload.')\n",
        "  issues_df = pd.concat([issues_df.drop('payload', axis=1), payload_flat], axis=1)\n",
        "  issues_df.to_csv('issues.csv', index=False)"
      ],
      "metadata": {
        "id": "lt4wq1VQpZAp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_to_blob_storage( connection_string, container_name, file_path, blob_name):\n",
        "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
        "    blob_client = blob_service_client.get_blob_client(container= container_name, blob= blob_name)\n",
        "\n",
        "    with open(file_path, \"rb\") as data:\n",
        "        blob_client.upload_blob(data)"
      ],
      "metadata": {
        "id": "DbhOoNjZrQal"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date = \"2023-06-10\"\n",
        "time = \"15\"\n",
        "connection_string = \"DefaultEndpointsProtocol=https;AccountName=pod4projectstorage;AccountKey=2hClDrVPLGX4QBDBk8OylAkHqczIQfDja66Yl488rmj/0+vb+CAzOxL5qMe5XyM9ZupgwveVRm3N+AStriO5vg==;EndpointSuffix=core.windows.net\"\n",
        "container_name = \"data\"\n",
        "file_path = \"issues.csv\"\n",
        "blob_name = \"issues.csv\"\n",
        "\n",
        "data = get_data(date,time)\n",
        "normalize_data()\n",
        "upload_to_blob_storage( connection_string, container_name, file_path, blob_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjMUAsQwrgnZ",
        "outputId": "29139534-2c3d-4dc9-9364-12efc037510d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://data.gharchive.org/2023-06-10-15.json.gz\n",
            "File downloaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-e98ab4d5d611>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  issues_df['payload'] = issues_df['payload'].apply(lambda row: format_payload(row))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4GQi-jyltQRJ"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}