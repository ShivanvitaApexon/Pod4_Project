# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Tne6e--bepCL2Jcr0pUvThGO9CrURdg1
"""

pip install scikit-learn

pip install azure.storage.blob

pip install cleantext

import requests
import os
import json
import numpy as np
import plotly
import plotly.graph_objects as go
import gzip
from sklearn.metrics import roc_curve, roc_auc_score,auc
import matplotlib.pyplot as plt
from sklearn.utils import resample
import cleantext
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from scipy.sparse import hstack

from sklearn import svm
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

import re

import pandas as pd
from sklearn.naive_bayes import MultinomialNB
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from imblearn.over_sampling import RandomOverSampler

import collections
import nltk
nltk.download('stopwords')
nltk.download('punkt')
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
from wordcloud import WordCloud
from nltk.corpus import stopwords
from nltk.corpus import words
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
import seaborn as sn
plt.style.use('fivethirtyeight')

from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient
from azure.core.pipeline.transport import HttpResponse

account_name = 'pod4projectstorage'
account_key = '2hClDrVPLGX4QBDBk8OylAkHqczIQfDja66Yl488rmj/0+vb+CAzOxL5qMe5XyM9ZupgwveVRm3N+AStriO5vg=='
container_name = 'issues1'
blob_name = '2023-06-06.snappy.parquet'

conn_string = f"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net"

blob_service_client = BlobServiceClient.from_connection_string(conn_string)

container_client = blob_service_client.get_container_client(container_name)

local_path = 'local_file.parquet'
with open(local_path, "wb") as file:
    blob_client = container_client.get_blob_client(blob_name)
    blob_data = blob_client.download_blob()
    blob_data.readinto(file)

df = pd.read_parquet(local_path)

df.head()

# Null Values
df[df.isnull().any(axis=1)]

# Target variable counts
k = df.target.value_counts()

colors = ['mediumturquoise', 'lightgreen','orange','gold']

labels = ['Bug','Enhancement','Request','Other']
values = [k.bug,k.enhancement,k.request, k.other]

fig = go.Figure(data=[go.Pie(labels=labels,
                             values=values)])
fig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,
                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))
fig.update_layout(title_text='Label Counts')
fig.show()

# Dropping Nulls
df.dropna(inplace=True)
df.shape

# Creating a new dataframe
newdf = df[['target','title','body']]
newdf['length_title'] = df['title'].apply(lambda x: len(x))
newdf['length_body'] = df['body'].apply(lambda x: len(x))

url_pattern = r"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"
newdf['body'] = newdf['body'].apply(lambda x:re.sub(url_pattern, "", x))

newdf = newdf.loc[newdf['body'].str.strip() != '']

newdf['body'] = newdf['body'].apply(lambda x: cleantext.clean(x)) # has urls
newdf['title'] = newdf['title'].apply(lambda x: cleantext.clean(x))
newdf.title = newdf.title.str.replace(r'[^A-Za-z\s]+', '', regex=True)
newdf.body = newdf.body.str.replace(r'[^A-Za-z\s]+', '', regex=True)

newdf = newdf.loc[newdf['body'].str.strip() != '']
newdf = newdf.loc[newdf['title'].str.strip() != '']

# Cleaning and preparing the data for NLP

stop_words = stopwords.words('english')
bug_text = newdf[newdf['target'] == 'bug']['title']
enh_text = newdf[newdf['target'] == 'enhancement']['title']
req_text = newdf[newdf['target'] == 'request']['title']
other_text = newdf[newdf['target'] == 'other']['title']

def clean_text(Text):
    words_list = Text.lower()
    words_list = word_tokenize(words_list)
    words_list = [word for word in words_list if word not in stop_words]
    return words_list

def counter(data):
    counter = collections.OrderedDict()
    for Text in data:
        words_list = clean_text(Text)
        for word in set(words_list):
            if word in counter:
                counter[word] += 1
            else:
                counter[word] = 1
    return counter

# Dictionary with count of unique word
bug_words = counter(bug_text)
enh_words = counter(enh_text)
req_words = counter(req_text)
other_words = counter(other_text)

# Wordcloud function
def wordcloud(words):
   wc = WordCloud(background_color="white", max_words=50,max_font_size=400)
   wc.generate_from_frequencies(words)

   plt.figure(figsize=(10, 5))
   plt.imshow(wc, interpolation="bilinear")
   plt.axis("off")
   plt.show()

# WordCloud for BUG words
wordcloud(bug_words)

# WordCloud for Feature or Enhancement words
wordcloud(enh_words)

# WordCloud for Request words
wordcloud(req_words)

# WordCloud for OTHER words
wordcloud(other_words)

label = newdf['target'].tolist()

colors = ['mediumturquoise', 'lightgreen','orange','gold']

labels = ['Bug','Enhancement','Request','Other']
values = [label.count('bug'),label.count('enhancement'),label.count('request'), label.count('other')]

fig = go.Figure(data=[go.Pie(labels=labels,
                             values=values)])
fig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,
                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))
fig.update_layout(title_text='Label Counts')
fig.show()



class_counts = newdf['target'].value_counts()
minority_class = class_counts.idxmin()

# Group-based Undersampling
df = newdf.groupby('target').apply(lambda x: x.sample(n=class_counts[minority_class], random_state=42)).reset_index(drop=True)

label1 = df['target'].tolist()
text1 = df['target'].tolist()

colors = ['mediumturquoise', 'lightgreen','orange','gold']

labels = ['Bug','Enhancement','Request','Other']
values = [label1.count('bug'),label1.count('enhancement'),label1.count('request'), label1.count('other')]

fig = go.Figure(data=[go.Pie(labels=labels,
                             values=values)])
fig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,
                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))
fig.update_layout(title_text='Label Counts')
fig.show()

# Naive Bayes

#Split the dataset
X_train, X_test, y_train, y_test = train_test_split(df.title, df.target, stratify=df.target, test_size=0.3, random_state=42)

# Vectorize the data
vectorizer = TfidfVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

# Training the model
naive_bayes = MultinomialNB()
naive_bayes.fit(X_train_vectorized, y_train)

# Evaluation
y_pred = naive_bayes.predict(X_test_vectorized)
print(classification_report(y_test, y_pred))
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Split the Data
# Stratified sampling is used because it takes same proportions that are originally in the data
X_train, X_test, y_train, y_test = train_test_split(newdf.title, newdf.target, test_size=0.3, stratify=newdf.target,random_state=42)

# Vectorize the Text
vectorizer = TfidfVectorizer()
X_train_features = vectorizer.fit_transform(X_train)
X_test_features = vectorizer.transform(X_test)

x = y_train.tolist()
colors = ['mediumturquoise', 'lightgreen','orange','gold']

labels = ['Bug','Enhancement','Request','Other']
values = [x.count('bug'),x.count('enhancement'),x.count('request'), x.count('other')]

fig = go.Figure(data=[go.Pie(labels=labels,
                             values=values)])
fig.update_traces(hoverinfo='label+percent', textinfo='value', textfont_size=20,
                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))
fig.update_layout(title_text='Label Counts')
fig.show()

# Train the Naive Bayes classifier
naive_bayes = MultinomialNB()
naive_bayes.fit(X_train_features, y_train)

# Evaluation
y_pred = naive_bayes.predict(X_test_features)
print(classification_report(y_test, y_pred))
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# SVM Model
svm_model = svm.SVC(kernel='rbf')
svm_model.fit(X_train_features, y_train)

# Evaluation
y_pred = svm_model.predict(X_test_features)
print(classification_report(y_test, y_pred))
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

y_pred_proba = svm_model.decision_function(X_test_features)

fpr = dict()
tpr = dict()
roc_auc = dict()
for i, class_label in enumerate(svm_model.classes_):
    fpr[i], tpr[i], _ = roc_curve(y_test == class_label, y_pred_proba[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(8, 5))
for i, class_label in enumerate(svm_model.classes_):
    plt.plot(fpr[i], tpr[i], label=f'Class {class_label} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('AUC-ROC Curve for SVM')
plt.legend()
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score, auc

# Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train_features, y_train)

# Evaluation
y_pred = rf_model.predict(X_test_features)
print(classification_report(y_test, y_pred))
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

y_pred_proba = rf_model.predict_proba(X_test_features)

fpr = dict()
tpr = dict()
roc_auc = dict()
for i, class_label in enumerate(rf_model.classes_):
    fpr[i], tpr[i], _ = roc_curve(y_test == class_label, y_pred_proba[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])


plt.figure(figsize=(8, 5))
for i, class_label in enumerate(rf_model.classes_):
    plt.plot(fpr[i], tpr[i], label=f'Class {class_label} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('AUC-ROC Curve for Random Forest')
plt.legend()
plt.show()

# Split the Data
X_train, X_test, y_train, y_test = train_test_split(newdf.body, newdf.target,stratify=newdf.target, test_size=0.3, random_state=42)

# Vectorize the Text
vectorizer = TfidfVectorizer()
X_train_features = vectorizer.fit_transform(X_train)
X_test_features = vectorizer.transform(X_test)

# Train the Naive Bayes classifier

naive_bayes = MultinomialNB()
naive_bayes.fit(X_train_features, y_train)

# Evaluation
y_pred = naive_bayes.predict(X_test_features)
print(classification_report(y_test, y_pred))
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# SVM Model

svm_model = svm.SVC(kernel='rbf')
svm_model.fit(X_train_features, y_train)

# Evaluation
y_pred = svm_model.predict(X_test_features)
print(classification_report(y_test, y_pred))
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

y_pred_proba = svm_model.decision_function(X_test_features)

fpr = dict()
tpr = dict()
roc_auc = dict()
for i, class_label in enumerate(svm_model.classes_):
    fpr[i], tpr[i], _ = roc_curve(y_test == class_label, y_pred_proba[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure(figsize=(8, 5))
for i, class_label in enumerate(svm_model.classes_):
    plt.plot(fpr[i], tpr[i], label=f'Class {class_label} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('AUC-ROC Curve for SVM')
plt.legend()
plt.show()

# Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train_features, y_train)

# Evaluation
y_pred = rf_model.predict(X_test_features)
print(classification_report(y_test, y_pred))
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

y_pred_proba = rf_model.predict_proba(X_test_features)

fpr = dict()
tpr = dict()
roc_auc = dict()
for i, class_label in enumerate(rf_model.classes_):
    fpr[i], tpr[i], _ = roc_curve(y_test == class_label, y_pred_proba[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])


plt.figure(figsize=(8, 5))
for i, class_label in enumerate(rf_model.classes_):
    plt.plot(fpr[i], tpr[i], label=f'Class {class_label} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('AUC-ROC Curve for Random Forest')
plt.legend()
plt.show()

X_text = newdf[['title', 'body']]
y = newdf['target']

X_train, X_test, y_train, y_test = train_test_split(X_text, y, test_size=0.2, random_state=42)
tfidf_vectorizer = TfidfVectorizer()
X_train_vectorized = tfidf_vectorizer.fit_transform(X_train.apply(lambda x: ' '.join(x), axis=1))
X_test_vectorized = tfidf_vectorizer.transform(X_test.apply(lambda x: ' '.join(x), axis=1))

# Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train_vectorized, y_train)

# Evaluation
y_pred = rf_model.predict(X_test_vectorized)
print(classification_report(y_test, y_pred))
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

y_pred_proba = rf_model.predict_proba(X_test_vectorized)

fpr = dict()
tpr = dict()
roc_auc = dict()
for i, class_label in enumerate(rf_model.classes_):
    fpr[i], tpr[i], _ = roc_curve(y_test == class_label, y_pred_proba[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])


plt.figure(figsize=(8, 5))
for i, class_label in enumerate(rf_model.classes_):
    plt.plot(fpr[i], tpr[i], label=f'Class {class_label} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('AUC-ROC Curve for Random Forest')
plt.legend()
plt.show()